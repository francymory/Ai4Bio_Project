{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x147b6c1f83f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os  # Per la gestione di file e directory\n",
    "import torch  # Per il modello e i tensori\n",
    "import torch.nn.functional as F  # Per interpolazione delle mappe di attenzione\n",
    "from torchvision.transforms import Compose, Resize, ToTensor  # Preprocessamento delle immagini\n",
    "from PIL import Image  # Per caricare immagini\n",
    "import matplotlib.pyplot as plt  # Per visualizzare heatmap e risultati\n",
    "import numpy as np  # Per manipolazioni numeriche\n",
    "from sklearn.cluster import KMeans  # Per clustering delle feature\n",
    "from conch.open_clip_custom import create_model_from_pretrained, tokenize, get_tokenizer\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import utils\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "# show all jupyter output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)  # For CPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)  # For GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import model\n",
    "\n",
    "model, preprocess = create_model_from_pretrained('conch_ViT-B-16', \"hf_hub:MahmoodLab/conch\", hf_auth_token=\"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\", device=device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Irregular mucosal surface', 'Ulceration', 'Thickened esophageal wall', 'Loss of normal vascular pattern', 'White plaques or keratinization', 'Narrowed lumen', 'Asymmetric growth or mass', 'Hypervascularity', 'Increased contrast uptake in imaging', 'Infiltrative margins', 'Irregular glandular structures', 'Mucinous or necrotic areas', 'Thickened esophageal wall', 'Ulcerated or fungating mass', 'Loss of normal mucosal pattern', \"Barrett's esophagus background\", 'Hypervascularity', 'Narrowed or obstructed lumen', 'Heterogeneous contrast enhancement', 'Infiltrative or exophytic growth pattern']\n",
      "{'Esophageal adenocarcinoma (ESAD)': 0, 'Esophageal squamous cell carcinoma (ESCC)': 1}\n"
     ]
    }
   ],
   "source": [
    "#load the classes and descriptors\n",
    "classifier_folder=\"classifiers_tumor\"\n",
    "all_descriptors=json.load(open(\"classifiers/\"+ classifier_folder + \"/all_descriptors.json\", 'r'))\n",
    "tumor_classes=json.load(open(\"classifiers/\"+ classifier_folder + \"/tumor_classes.json\", 'r'))\n",
    "print(all_descriptors)\n",
    "\n",
    "\n",
    "#build mapping from classes to id\n",
    "class_index_file= json.load(open('classifiers/class_index.json','r'))\n",
    "folder2id={v[0]:int(k) for k,v in class_index_file.items()}\n",
    "print(folder2id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the textual embeddings and the classes/descriptors similarity matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes embeddings shape: torch.Size([2, 512])\n",
      "Descriptors embeddings shape: torch.Size([20, 512])\n",
      "Sim Matrix shape: torch.Size([2, 20])\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "tokenizer = get_tokenizer()\n",
    "classes_tokens = tokenize(texts=tumor_classes, tokenizer=tokenizer).to(device)\n",
    "descriptors_tokens= tokenize(texts=all_descriptors, tokenizer=tokenizer ).to(device)\n",
    "\n",
    "\n",
    "\n",
    "#compute embeddings and similarity matrix, with the relevance between each class and descriptor\n",
    "with torch.inference_mode():\n",
    "    classes_embeddings = model.encode_text(classes_tokens)\n",
    "    descriptors_embeddings = model.encode_text(descriptors_tokens)\n",
    "    print(\"Classes embeddings shape:\", classes_embeddings.shape)\n",
    "    print(\"Descriptors embeddings shape:\",descriptors_embeddings.shape)\n",
    "    similarity_matrix=classes_embeddings @ descriptors_embeddings.T  # Shape: (num_classi, num_concetti)\n",
    "    print(\"Sim Matrix shape:\", similarity_matrix.shape)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the visual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif not os.path.exists(esad_dir):\\n    os.makedirs(esad_dir)\\n\\nif not os.path.exists(escc_dir):\\n    os.makedirs(escc_dir)\\n\\n# load the dataset as dataframe\\ntry:\\n    df = pd.read_csv(csv_path)\\n    print(\"CSV caricato con successo!\")\\nexcept Exception as e:\\n    print(f\"Errore nel caricamento del CSV: {e}\")\\n    raise\\nprint(df.columns)\\n\\n\\nif \"slide\" not in df.columns or \"labels\" not in df.columns:\\n    raise ValueError(\"Il CSV deve contenere le colonne \\'filename\\' e \\'label\\'\")\\n\\n\\nfor _, row in df.iterrows():\\n    file_name = row[\"slide\"]\\n    label = row[\"labels\"]\\n    \\n    \\n    src_path = file_name  # originale file path es: /work/h2020deciderficarra_shared/fmorandi/data/feats_conch_slide/TCGA-LN-A7HY-01Z-00-DX1_0.pkl\\n\\n    \\n    # Determines right directory\\n    if label == 0:\\n        dest_path = os.path.join(esad_dir, os.path.basename(file_name))\\n    elif label == 1:\\n        dest_path = os.path.join(escc_dir, os.path.basename(file_name))\\n    else:\\n        continue\\n    \\n    # Copiees file in the right directory\\n    if os.path.exists(src_path):\\n        shutil.copy(src_path, dest_path)\\n        print(f\"Copiato: {src_path} -> {dest_path}\")\\n    else:\\n        print(f\"File non trovato: {src_path}\")\\nprint(\"Copia completata!\")\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the patch embeddings in two different directories, according to their labels: 0-> ESAD, 1->ESCC\n",
    "\n",
    "# file CSV\n",
    "csv_path = \"/homes/fmorandi/ai4bio_project/dataset_esca.csv\"\n",
    "\n",
    "# destination directories\n",
    "esad_dir = \"/homes/fmorandi/ai4bio_project/images/esad\"\n",
    "escc_dir = \"/homes/fmorandi/ai4bio_project/images/escc\"\n",
    "'''\n",
    "if not os.path.exists(esad_dir):\n",
    "    os.makedirs(esad_dir)\n",
    "\n",
    "if not os.path.exists(escc_dir):\n",
    "    os.makedirs(escc_dir)\n",
    "\n",
    "# load the dataset as dataframe\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV caricato con successo!\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore nel caricamento del CSV: {e}\")\n",
    "    raise\n",
    "print(df.columns)\n",
    "\n",
    "\n",
    "if \"slide\" not in df.columns or \"labels\" not in df.columns:\n",
    "    raise ValueError(\"Il CSV deve contenere le colonne 'filename' e 'label'\")\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    file_name = row[\"slide\"]\n",
    "    label = row[\"labels\"]\n",
    "    \n",
    "    \n",
    "    src_path = file_name  # originale file path es: /work/h2020deciderficarra_shared/fmorandi/data/feats_conch_slide/TCGA-LN-A7HY-01Z-00-DX1_0.pkl\n",
    "\n",
    "    \n",
    "    # Determines right directory\n",
    "    if label == 0:\n",
    "        dest_path = os.path.join(esad_dir, os.path.basename(file_name))\n",
    "    elif label == 1:\n",
    "        dest_path = os.path.join(escc_dir, os.path.basename(file_name))\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Copiees file in the right directory\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.copy(src_path, dest_path)\n",
    "        print(f\"Copiato: {src_path} -> {dest_path}\")\n",
    "    else:\n",
    "        print(f\"File non trovato: {src_path}\")\n",
    "print(\"Copia completata!\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo di dato caricato: <class 'dict'>\n",
      "Chiavi presenti nel dizionario: dict_keys(['region', 'patch'])\n",
      "torch.Size([186, 512])\n",
      "torch.Size([186, 8, 8, 512])\n"
     ]
    }
   ],
   "source": [
    "#see how an embedding is made\n",
    "import pickle\n",
    "\n",
    "pkl_path = \"/homes/fmorandi/ai4bio_project/images/escc/TCGA-2H-A9GG-01Z-00-DX1_1.pkl\"\n",
    "\n",
    "\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(f\"Tipo di dato caricato: {type(data)}\")\n",
    "print(\"Chiavi presenti nel dizionario:\", data.keys())\n",
    "print(data[\"region\"].shape) #minore risoluzione ->usa questo -> shape (N variabile, 512)\n",
    "print(data[\"patch\"].shape) #maggiore risoluzione\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ai4bio)",
   "language": "python",
   "name": "ai4bio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
